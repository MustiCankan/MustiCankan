{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "6FMVr1X1je1X",
        "outputId": "87293362-5951-4350-a237-9c6c7c109049",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting git+https://github.com/openai/glide-text2im\n",
            "  Cloning https://github.com/openai/glide-text2im to /tmp/pip-req-build-40q_pztc\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/openai/glide-text2im /tmp/pip-req-build-40q_pztc\n",
            "  Resolved https://github.com/openai/glide-text2im to commit 69b530740eb6cef69442d6180579ef5ba9ef063e\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.10/dist-packages (from glide-text2im==0.0.0) (11.0.0)\n",
            "Requirement already satisfied: attrs in /usr/local/lib/python3.10/dist-packages (from glide-text2im==0.0.0) (24.3.0)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from glide-text2im==0.0.0) (2.5.1+cu121)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from glide-text2im==0.0.0) (3.16.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from glide-text2im==0.0.0) (2.32.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from glide-text2im==0.0.0) (4.67.1)\n",
            "Collecting ftfy (from glide-text2im==0.0.0)\n",
            "  Downloading ftfy-6.3.1-py3-none-any.whl.metadata (7.3 kB)\n",
            "Requirement already satisfied: regex in /usr/local/lib/python3.10/dist-packages (from glide-text2im==0.0.0) (2024.11.6)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from glide-text2im==0.0.0) (1.26.4)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.10/dist-packages (from ftfy->glide-text2im==0.0.0) (0.2.13)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->glide-text2im==0.0.0) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->glide-text2im==0.0.0) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->glide-text2im==0.0.0) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->glide-text2im==0.0.0) (2024.12.14)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch->glide-text2im==0.0.0) (4.12.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch->glide-text2im==0.0.0) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch->glide-text2im==0.0.0) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch->glide-text2im==0.0.0) (2024.10.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch->glide-text2im==0.0.0) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch->glide-text2im==0.0.0) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch->glide-text2im==0.0.0) (3.0.2)\n",
            "Downloading ftfy-6.3.1-py3-none-any.whl (44 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.8/44.8 kB\u001b[0m \u001b[31m3.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hBuilding wheels for collected packages: glide-text2im\n",
            "  Building wheel for glide-text2im (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for glide-text2im: filename=glide_text2im-0.0.0-py3-none-any.whl size=1953624 sha256=ce76fc5a7d748066fdd76703726ba29ee6706100ec608ad22ae84a5487ddcf58\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-6cnvorxg/wheels/88/21/5e/57cab1c1078317022fe11d86e1596fdaa12260531220ac0c99\n",
            "Successfully built glide-text2im\n",
            "Installing collected packages: ftfy, glide-text2im\n",
            "Successfully installed ftfy-6.3.1 glide-text2im-0.0.0\n"
          ]
        }
      ],
      "source": [
        "# Run this line in Colab to install the package if it is\n",
        "# not already installed.\n",
        "!pip install git+https://github.com/openai/glide-text2im"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "B145cF9Jje1Y"
      },
      "outputs": [],
      "source": [
        "from PIL import Image\n",
        "from IPython.display import display\n",
        "import torch as th\n",
        "import torch.nn as nn\n",
        "\n",
        "from glide_text2im.clip.model_creation import create_clip_model\n",
        "from glide_text2im.download import load_checkpoint\n",
        "from glide_text2im.model_creation import (\n",
        "    create_model_and_diffusion,\n",
        "    model_and_diffusion_defaults,\n",
        "    model_and_diffusion_defaults_upsampler,\n",
        ")\n",
        "from glide_text2im.tokenizer.simple_tokenizer import SimpleTokenizer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "3lR7o0Mmje1Y"
      },
      "outputs": [],
      "source": [
        "# This notebook supports both CPU and GPU.\n",
        "# On CPU, generating one sample may take on the order of 20 minutes.\n",
        "# On a GPU, it should be under a minute.\n",
        "\n",
        "has_cuda = th.cuda.is_available()\n",
        "device = th.device('cpu' if not has_cuda else 'cuda')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "9OG-F5eEje1Z",
        "outputId": "c5c9330f-aea9-462d-d0d9-357ab05342ea",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 123,
          "referenced_widgets": [
            "1862706a7fbb49c09724456271e476be",
            "e83343ae84ab457792bc9c5dd22454e6",
            "e02f566768f844b09943e81aefbc57ab",
            "5425488fa6ea44c59d33b79b69de0ba3",
            "e434551fc5ba4c89a3dfafdb660be64b",
            "89db4f3ae5f04ce29988e353a2d054a1",
            "d9c87f230e474acd8f601940a51e598b",
            "ed50012aaecb4859861bb84df7647e1f",
            "165c3c404b9543fca4cb94f0890b834f",
            "3e767df9450540498a177895985910a4",
            "6569f0a6c9764d9eaaed915d40c7626b"
          ]
        }
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0.00/1.54G [00:00<?, ?iB/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "1862706a7fbb49c09724456271e476be"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/glide_text2im/download.py:71: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  return th.load(path, map_location=device)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "total base parameters 385030726\n"
          ]
        }
      ],
      "source": [
        "# Create base model.\n",
        "options = model_and_diffusion_defaults()\n",
        "options['use_fp16'] = has_cuda\n",
        "options['timestep_respacing'] = '100' # use 100 diffusion steps for fast sampling\n",
        "model, diffusion = create_model_and_diffusion(**options)\n",
        "model.eval()\n",
        "if has_cuda:\n",
        "    model.convert_to_fp16()\n",
        "model.to(device)\n",
        "model.load_state_dict(load_checkpoint('base', device))\n",
        "print('total base parameters', sum(x.numel() for x in model.parameters()))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "LkqikQngje1Z",
        "outputId": "ec9d4fbe-c86f-43c6-d52d-cf8b64bc4219",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 67,
          "referenced_widgets": [
            "2a2ac0e906c34afab1c64c35c96b7312",
            "e76e3ea16d3f4817996807ae27a0a19d",
            "6dda19c93aa14650826872812c1f50ff",
            "1fb5cc5e2a1644a09b6de6f73bf9fecd",
            "196f1dbc86514c72929a4f9684471583",
            "38b089e725ec4f4e8b13b748334bc81b",
            "1840e09ae2fd485fad231266fce5e1b8",
            "93d88c9b1ab8480cb3484b30b124715c",
            "fac158b076564e58a8fd0306b12f734c",
            "6440591ad6164793af6557798bb3fa9c",
            "1c73465f53da4b56b4b7fbddbb8c3eb4"
          ]
        }
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0.00/1.59G [00:00<?, ?iB/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "2a2ac0e906c34afab1c64c35c96b7312"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "total upsampler parameters 398361286\n"
          ]
        }
      ],
      "source": [
        "# Create upsampler model.\n",
        "options_up = model_and_diffusion_defaults_upsampler()\n",
        "options_up['use_fp16'] = has_cuda\n",
        "options_up['timestep_respacing'] = 'fast27' # use 27 diffusion steps for very fast sampling\n",
        "model_up, diffusion_up = create_model_and_diffusion(**options_up)\n",
        "model_up.eval()\n",
        "if has_cuda:\n",
        "    model_up.convert_to_fp16()\n",
        "model_up.to(device)\n",
        "model_up.load_state_dict(load_checkpoint('upsample', device))\n",
        "print('total upsampler parameters', sum(x.numel() for x in model_up.parameters()))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "xr_GbXzMje1Z",
        "outputId": "27dccecd-2f7f-4ba0-a1c1-3cb7ca71875e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 653
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/glide_text2im/clip/attention.py:111: FutureWarning: In the future `np.bool` will be defined as the corresponding NumPy scalar.\n",
            "  self.global_layout = np.tril(np.ones([self.n_query_block, self.n_key_block], dtype=np.bool))\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "module 'numpy' has no attribute 'bool'.\n`np.bool` was a deprecated alias for the builtin `bool`. To avoid this error in existing code, use `bool` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.bool_` here.\nThe aliases was originally deprecated in NumPy 1.20; for more details and guidance see the original release note at:\n    https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-6-f8b7050f856d>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Create CLIP model.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mclip_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcreate_clip_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mclip_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimage_encoder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_state_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mload_checkpoint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'clip/image-enc'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mclip_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtext_encoder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_state_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mload_checkpoint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'clip/text-enc'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/glide_text2im/clip/model_creation.py\u001b[0m in \u001b[0;36mcreate_clip_model\u001b[0;34m(config_path, device, tokenizer)\u001b[0m\n\u001b[1;32m     80\u001b[0m         \u001b[0mconfig\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0myaml\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mLoader\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0myaml\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSafeLoader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     81\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 82\u001b[0;31m     text_encoder = TextEncoder(\n\u001b[0m\u001b[1;32m     83\u001b[0m         \u001b[0mn_bpe_vocab\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"n_vocab\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     84\u001b[0m         \u001b[0mmax_text_len\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"max_text_len\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/glide_text2im/clip/encoders.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, n_bpe_vocab, max_text_len, n_embd, n_head, n_xf_blocks, n_head_state, device)\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mblock_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mattr_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'block_size'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdefault\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__attrs_post_init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/glide_text2im/clip/encoders.py\u001b[0m in \u001b[0;36m__attrs_post_init__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    363\u001b[0m             \u001b[0mn_pad\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    364\u001b[0m         )\n\u001b[0;32m--> 365\u001b[0;31m         \u001b[0mmask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDenseCausalAttentionMask\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    366\u001b[0m         \u001b[0mattn_fn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_attention_info\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    367\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/glide_text2im/clip/attention.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, query_context_size, key_context_size, block_size, n_head, is_head_specific, n_query_pad, n_key_pad)\u001b[0m\n\u001b[1;32m     12\u001b[0m         \u001b[0m__attr_validator_block_size\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m__attr_block_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mblock_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0m__attr_validator_n_head\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m__attr_n_head\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_head\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__attrs_post_init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/glide_text2im/clip/attention.py\u001b[0m in \u001b[0;36m__attrs_post_init__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    109\u001b[0m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__attrs_post_init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 111\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mglobal_layout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtril\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mones\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_query_block\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_key_block\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbool\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    112\u001b[0m         \u001b[0mn_zero_query_blocks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_query_pad\u001b[0m \u001b[0;34m//\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mblock_size\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    113\u001b[0m         \u001b[0mn_zero_key_blocks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_key_pad\u001b[0m \u001b[0;34m//\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mblock_size\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/numpy/__init__.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(attr)\u001b[0m\n\u001b[1;32m    322\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    323\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mattr\u001b[0m \u001b[0;32min\u001b[0m \u001b[0m__former_attrs__\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 324\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mAttributeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m__former_attrs__\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mattr\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    325\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    326\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mattr\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'testing'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: module 'numpy' has no attribute 'bool'.\n`np.bool` was a deprecated alias for the builtin `bool`. To avoid this error in existing code, use `bool` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.bool_` here.\nThe aliases was originally deprecated in NumPy 1.20; for more details and guidance see the original release note at:\n    https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations"
          ]
        }
      ],
      "source": [
        "# Create CLIP model.\n",
        "clip_model = create_clip_model(device=device)\n",
        "clip_model.image_encoder.load_state_dict(load_checkpoint('clip/image-enc', device))\n",
        "clip_model.text_encoder.load_state_dict(load_checkpoint('clip/text-enc', device))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bw8P8aHbje1Z"
      },
      "outputs": [],
      "source": [
        "def show_images(batch: th.Tensor):\n",
        "    \"\"\" Display a batch of images inline. \"\"\"\n",
        "    scaled = ((batch + 1)*127.5).round().clamp(0,255).to(th.uint8).cpu()\n",
        "    reshaped = scaled.permute(2, 0, 3, 1).reshape([batch.shape[2], -1, 3])\n",
        "    display(Image.fromarray(reshaped.numpy()))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "K0B5PWnPje1a"
      },
      "outputs": [],
      "source": [
        "# Sampling parameters\n",
        "prompt = \"an oil painting of a corgi\"\n",
        "batch_size = 1\n",
        "guidance_scale = 3.0\n",
        "\n",
        "# Tune this parameter to control the sharpness of 256x256 images.\n",
        "# A value of 1.0 is sharper, but sometimes results in grainy artifacts.\n",
        "upsample_temp = 0.997"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pCkCRj4Oje1a"
      },
      "outputs": [],
      "source": [
        "##############################\n",
        "# Sample from the base model #\n",
        "##############################\n",
        "\n",
        "# Create the text tokens to feed to the model.\n",
        "tokens = model.tokenizer.encode(prompt)\n",
        "tokens, mask = model.tokenizer.padded_tokens_and_mask(\n",
        "    tokens, options['text_ctx']\n",
        ")\n",
        "\n",
        "# Pack the tokens together into model kwargs.\n",
        "model_kwargs = dict(\n",
        "    tokens=th.tensor([tokens] * batch_size, device=device),\n",
        "    mask=th.tensor([mask] * batch_size, dtype=th.bool, device=device),\n",
        ")\n",
        "\n",
        "# Setup guidance function for CLIP model.\n",
        "cond_fn = clip_model.cond_fn([prompt] * batch_size, guidance_scale)\n",
        "\n",
        "# Sample from the base model.\n",
        "model.del_cache()\n",
        "samples = diffusion.p_sample_loop(\n",
        "    model,\n",
        "    (batch_size, 3, options[\"image_size\"], options[\"image_size\"]),\n",
        "    device=device,\n",
        "    clip_denoised=True,\n",
        "    progress=True,\n",
        "    model_kwargs=model_kwargs,\n",
        "    cond_fn=cond_fn,\n",
        ")\n",
        "model.del_cache()\n",
        "\n",
        "# Show the output\n",
        "show_images(samples)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "34DbH4yDje1a"
      },
      "outputs": [],
      "source": [
        "##############################\n",
        "# Upsample the 64x64 samples #\n",
        "##############################\n",
        "\n",
        "tokens = model_up.tokenizer.encode(prompt)\n",
        "tokens, mask = model_up.tokenizer.padded_tokens_and_mask(\n",
        "    tokens, options_up['text_ctx']\n",
        ")\n",
        "\n",
        "# Create the model conditioning dict.\n",
        "model_kwargs = dict(\n",
        "    # Low-res image to upsample.\n",
        "    low_res=((samples+1)*127.5).round()/127.5 - 1,\n",
        "\n",
        "    # Text tokens\n",
        "    tokens=th.tensor(\n",
        "        [tokens] * batch_size, device=device\n",
        "    ),\n",
        "    mask=th.tensor(\n",
        "        [mask] * batch_size,\n",
        "        dtype=th.bool,\n",
        "        device=device,\n",
        "    ),\n",
        ")\n",
        "\n",
        "# Sample from the base model.\n",
        "model_up.del_cache()\n",
        "up_shape = (batch_size, 3, options_up[\"image_size\"], options_up[\"image_size\"])\n",
        "up_samples = diffusion_up.ddim_sample_loop(\n",
        "    model_up,\n",
        "    up_shape,\n",
        "    noise=th.randn(up_shape, device=device) * upsample_temp,\n",
        "    device=device,\n",
        "    clip_denoised=True,\n",
        "    progress=True,\n",
        "    model_kwargs=model_kwargs,\n",
        "    cond_fn=None,\n",
        ")[:batch_size]\n",
        "model_up.del_cache()\n",
        "\n",
        "# Show the output\n",
        "show_images(up_samples)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!wget http://images.cocodataset.org/zips/train2017.zip\n",
        "!unzip train2017.zip -d data/coco"
      ],
      "metadata": {
        "id": "KKNY240SjoLN",
        "outputId": "210d600c-93d0-4373-97a1-f71a4d9e6057",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2025-01-07 21:09:28--  http://images.cocodataset.org/zips/train2017.zip\n",
            "Resolving images.cocodataset.org (images.cocodataset.org)... 3.5.30.165, 3.5.29.147, 52.216.36.177, ...\n",
            "Connecting to images.cocodataset.org (images.cocodataset.org)|3.5.30.165|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 19336861798 (18G) [application/zip]\n",
            "Saving to: ‘train2017.zip’\n",
            "\n",
            "train2017.zip       100%[===================>]  18.01G  16.6MB/s    in 18m 57s \n",
            "\n",
            "2025-01-07 21:28:26 (16.2 MB/s) - ‘train2017.zip’ saved [19336861798/19336861798]\n",
            "\n",
            "Archive:  train2017.zip\n",
            "checkdir:  cannot create extraction directory: data/coco\n",
            "           No such file or directory\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision import transforms\n",
        "from PIL import Image\n",
        "from glide_text2im.model_creation import create_model_and_diffusion\n",
        "from glide_text2im.tokenizer.simple_tokenizer import SimpleTokenizer\n",
        "from datasets import load_dataset\n",
        "\n",
        "# Function to preprocess image and tokenize caption\n",
        "def preprocess_image_and_caption(image_path, caption, tokenizer, image_size=256):\n",
        "    # Load and resize the image\n",
        "    image = Image.open(image_path).convert(\"RGB\")\n",
        "    transform = transforms.Compose([\n",
        "        transforms.Resize((image_size, image_size)),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize([0.5, 0.5, 0.5], [0.5, 0.5, 0.5]),\n",
        "    ])\n",
        "    image = transform(image)\n",
        "\n",
        "    # Tokenize the caption\n",
        "    tokens = tokenizer.encode(caption)\n",
        "    tokens = torch.tensor(tokens, dtype=torch.long)\n",
        "    return image, tokens\n",
        "\n",
        "\n",
        "# Model and diffusion process\n",
        "def load_glide_model(device):\n",
        "    model, diffusion = create_model_and_diffusion(\n",
        "        model_type=\"base\",  # \"base\" for 64x64, \"upsample\" for 256x256\n",
        "        timestep_respacing=\"ddim50\",  # Use 50 timesteps for faster training\n",
        "    )\n",
        "    model.to(device)\n",
        "    model.eval()\n",
        "    return model, diffusion\n",
        "\n",
        "\n",
        "# COCO Dataset Preparation\n",
        "def get_coco_dataloader(batch_size):\n",
        "    coco_data = load_dataset(\"coco_captions\", split=\"train\")\n",
        "    tokenizer = SimpleTokenizer()\n",
        "    transform = transforms.Compose([\n",
        "        transforms.Resize((256, 256)),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize([0.5, 0.5, 0.5], [0.5, 0.5, 0.5]),\n",
        "    ])\n",
        "\n",
        "    def coco_collate_fn(batch):\n",
        "        images, tokens = zip(*batch)\n",
        "        return torch.stack(images), torch.stack(tokens)\n",
        "\n",
        "    def coco_dataset():\n",
        "        for sample in coco_data:\n",
        "            image_path = f\"data/coco/images/train2017/{sample['image_id']:012d}.jpg\"\n",
        "            caption = sample[\"caption\"]\n",
        "            yield preprocess_image_and_caption(image_path, caption, tokenizer)\n",
        "\n",
        "    return DataLoader(list(coco_dataset()), batch_size=batch_size, shuffle=True, collate_fn=coco_collate_fn)\n",
        "\n",
        "\n",
        "# Training Loop\n",
        "def train_glide(model, diffusion, dataloader, optimizer, device, num_epochs=10):\n",
        "    model.train()\n",
        "    for epoch in range(num_epochs):\n",
        "        total_loss = 0.0\n",
        "        for i, (images, tokens) in enumerate(dataloader):\n",
        "            images, tokens = images.to(device), tokens.to(device)\n",
        "\n",
        "            # Forward pass through GLIDE diffusion\n",
        "            t = torch.randint(0, diffusion.num_timesteps, (images.size(0),), device=device)\n",
        "            noise = torch.randn_like(images)\n",
        "            noisy_images = diffusion.q_sample(images, t)\n",
        "            loss = diffusion.p_loss(model, noisy_images, tokens, t, noise)\n",
        "\n",
        "            # Backpropagation and optimization\n",
        "            optimizer.zero_grad()\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            total_loss += loss.item()\n",
        "\n",
        "            if i % 10 == 0:\n",
        "                print(f\"Epoch [{epoch+1}], Step [{i}], Loss: {loss.item():.4f}\")\n",
        "\n",
        "        avg_loss = total_loss / len(dataloader)\n",
        "        print(f\"Epoch [{epoch+1}/{num_epochs}] completed. Average Loss: {avg_loss:.4f}\")\n",
        "\n",
        "    torch.save(model.state_dict(), \"glide_model_coco.pth\")\n",
        "    print(\"Training completed and model saved!\")\n",
        "\n",
        "\n",
        "# Main function\n",
        "def main():\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "    model, diffusion = load_glide_model(device)\n",
        "\n",
        "    dataloader = get_coco_dataloader(batch_size=8)\n",
        "    optimizer = torch.optim.AdamW(model.parameters(), lr=1e-4)\n",
        "\n",
        "    train_glide(model, diffusion, dataloader, optimizer, device, num_epochs=5)\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ],
      "metadata": {
        "id": "tayVNlM2jmtT",
        "outputId": "82f7e37c-352d-4868-82f7-d46406d4cd14",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 500
        }
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ModuleNotFoundError",
          "evalue": "No module named 'datasets'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-8-a0b61c06e05c>\u001b[0m in \u001b[0;36m<cell line: 7>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mglide_text2im\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel_creation\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcreate_model_and_diffusion\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mglide_text2im\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtokenizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msimple_tokenizer\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mSimpleTokenizer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mdatasets\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mload_dataset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;31m# Function to preprocess image and tokenize caption\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'datasets'",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ],
          "errorDetails": {
            "actions": [
              {
                "action": "open_url",
                "actionText": "Open Examples",
                "url": "/notebooks/snippets/importing_libraries.ipynb"
              }
            ]
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install dataset"
      ],
      "metadata": {
        "id": "FNXthYeIq2hr",
        "outputId": "8278e001-8192-439f-a5b9-45789fc4eeb1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting dataset\n",
            "  Downloading dataset-1.6.2-py2.py3-none-any.whl.metadata (1.9 kB)\n",
            "Collecting sqlalchemy<2.0.0,>=1.3.2 (from dataset)\n",
            "  Downloading SQLAlchemy-1.4.54-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (10 kB)\n",
            "Collecting alembic>=0.6.2 (from dataset)\n",
            "  Downloading alembic-1.14.0-py3-none-any.whl.metadata (7.4 kB)\n",
            "Collecting banal>=1.0.1 (from dataset)\n",
            "  Downloading banal-1.0.6-py2.py3-none-any.whl.metadata (1.4 kB)\n",
            "Collecting Mako (from alembic>=0.6.2->dataset)\n",
            "  Downloading Mako-1.3.8-py3-none-any.whl.metadata (2.9 kB)\n",
            "Requirement already satisfied: typing-extensions>=4 in /usr/local/lib/python3.10/dist-packages (from alembic>=0.6.2->dataset) (4.12.2)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from sqlalchemy<2.0.0,>=1.3.2->dataset) (3.1.1)\n",
            "Requirement already satisfied: MarkupSafe>=0.9.2 in /usr/local/lib/python3.10/dist-packages (from Mako->alembic>=0.6.2->dataset) (3.0.2)\n",
            "Downloading dataset-1.6.2-py2.py3-none-any.whl (18 kB)\n",
            "Downloading alembic-1.14.0-py3-none-any.whl (233 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m233.5/233.5 kB\u001b[0m \u001b[31m21.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading banal-1.0.6-py2.py3-none-any.whl (6.1 kB)\n",
            "Downloading SQLAlchemy-1.4.54-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m70.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading Mako-1.3.8-py3-none-any.whl (78 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.6/78.6 kB\u001b[0m \u001b[31m6.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: banal, sqlalchemy, Mako, alembic, dataset\n",
            "  Attempting uninstall: sqlalchemy\n",
            "    Found existing installation: SQLAlchemy 2.0.36\n",
            "    Uninstalling SQLAlchemy-2.0.36:\n",
            "      Successfully uninstalled SQLAlchemy-2.0.36\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "ipython-sql 0.5.0 requires sqlalchemy>=2.0, but you have sqlalchemy 1.4.54 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed Mako-1.3.8 alembic-1.14.0 banal-1.0.6 dataset-1.6.2 sqlalchemy-1.4.54\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Q3O_IspWq8np"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "interpreter": {
      "hash": "e7d6e62d90e7e85f9a0faa7f0b1d576302d7ae6108e9fe361594f8e1c8b05781"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.3"
    },
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "1862706a7fbb49c09724456271e476be": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_e83343ae84ab457792bc9c5dd22454e6",
              "IPY_MODEL_e02f566768f844b09943e81aefbc57ab",
              "IPY_MODEL_5425488fa6ea44c59d33b79b69de0ba3"
            ],
            "layout": "IPY_MODEL_e434551fc5ba4c89a3dfafdb660be64b"
          }
        },
        "e83343ae84ab457792bc9c5dd22454e6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_89db4f3ae5f04ce29988e353a2d054a1",
            "placeholder": "​",
            "style": "IPY_MODEL_d9c87f230e474acd8f601940a51e598b",
            "value": "100%"
          }
        },
        "e02f566768f844b09943e81aefbc57ab": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ed50012aaecb4859861bb84df7647e1f",
            "max": 1540366691,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_165c3c404b9543fca4cb94f0890b834f",
            "value": 1540366691
          }
        },
        "5425488fa6ea44c59d33b79b69de0ba3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3e767df9450540498a177895985910a4",
            "placeholder": "​",
            "style": "IPY_MODEL_6569f0a6c9764d9eaaed915d40c7626b",
            "value": " 1.54G/1.54G [04:14&lt;00:00, 6.70MiB/s]"
          }
        },
        "e434551fc5ba4c89a3dfafdb660be64b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "89db4f3ae5f04ce29988e353a2d054a1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d9c87f230e474acd8f601940a51e598b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ed50012aaecb4859861bb84df7647e1f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "165c3c404b9543fca4cb94f0890b834f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "3e767df9450540498a177895985910a4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6569f0a6c9764d9eaaed915d40c7626b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "2a2ac0e906c34afab1c64c35c96b7312": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_e76e3ea16d3f4817996807ae27a0a19d",
              "IPY_MODEL_6dda19c93aa14650826872812c1f50ff",
              "IPY_MODEL_1fb5cc5e2a1644a09b6de6f73bf9fecd"
            ],
            "layout": "IPY_MODEL_196f1dbc86514c72929a4f9684471583"
          }
        },
        "e76e3ea16d3f4817996807ae27a0a19d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_38b089e725ec4f4e8b13b748334bc81b",
            "placeholder": "​",
            "style": "IPY_MODEL_1840e09ae2fd485fad231266fce5e1b8",
            "value": "100%"
          }
        },
        "6dda19c93aa14650826872812c1f50ff": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_93d88c9b1ab8480cb3484b30b124715c",
            "max": 1593693639,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_fac158b076564e58a8fd0306b12f734c",
            "value": 1593693639
          }
        },
        "1fb5cc5e2a1644a09b6de6f73bf9fecd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6440591ad6164793af6557798bb3fa9c",
            "placeholder": "​",
            "style": "IPY_MODEL_1c73465f53da4b56b4b7fbddbb8c3eb4",
            "value": " 1.59G/1.59G [04:25&lt;00:00, 6.86MiB/s]"
          }
        },
        "196f1dbc86514c72929a4f9684471583": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "38b089e725ec4f4e8b13b748334bc81b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1840e09ae2fd485fad231266fce5e1b8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "93d88c9b1ab8480cb3484b30b124715c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fac158b076564e58a8fd0306b12f734c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "6440591ad6164793af6557798bb3fa9c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1c73465f53da4b56b4b7fbddbb8c3eb4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}